# AI backend env template
# Required
INNER_CALLS_KEY=change-me-shared-secret

# RAG wiring (set to deployed/local RAG base URL)
RAG_URL=http://127.0.0.1:8001

# LLM provider routing: ollama | openai | cocoon
LLM_PROVIDER=ollama
OLLAMA_URL=http://127.0.0.1:11434
OLLAMA_MODEL=qwen2.5:1.5b

# Optional OpenAI fallback
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini

# Optional: local Cocoon client (OpenAI-compatible API). Run cocoon with shell/run-cocoon-local.sh first.
# LLM_PROVIDER=cocoon
# COCOON_CLIENT_URL=http://127.0.0.1:10000
# COCOON_MODEL=default

# Optional compatibility alias still accepted:
# API_KEY=change-me-shared-secret
